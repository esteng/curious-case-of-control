{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from experiment import Experiment\n",
    "from api_tools import (FixedGPTPrompt, \n",
    "                       FixedPassiveGPTPrompt, \n",
    "                       FixedT5Prompt, \n",
    "                       FixedPassiveT5Prompt, \n",
    "                       run_ai21_prompt, \n",
    "                       run_gpt_prompt, \n",
    "                       run_t5_prompt)\n",
    "\n",
    "from metrics import accuracy_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject Control\n",
    "Starting with the **subject** control experiments, we will look at how 4 LMs do:\n",
    "1. GPT3\n",
    "2. T5 for QA \n",
    "3. Jurassic large \n",
    "4. Jurassic Jumbo\n",
    "\n",
    "## Experimental settings\n",
    "We're looking at different name pairs to control for gender. We have 2 male-female name pairs, 1 male-male pair, 1 female-female pair, and 1 neutral-neutral. \n",
    "We're still looking at 5 different actions, but only one verb: promise. \n",
    "\n",
    "We can later coerce (with gender) subject control on \"suggested\" and \"proposed\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = [(\"Tom\", \"Mary\"), (\"Tom\", \"Bill\"), (\"Mary\", \"Bill\"), (\"Ellen\", \"Mary\"), (\"Morgan\", \"Jaime\"), (\"Iago\", \"Hamlet\"), (\"Jules\", \"Yves\"), (\"Kurt\", \"Lena\")]\n",
    "names = [(\"Tom\", \"Mary\"), (\"Tom\", \"Bill\"), (\"Mary\", \"Bill\"), (\"Ellen\", \"Mary\"), (\"Morgan\", \"Jaime\")]\n",
    "# verbs = [\"told\", \"ordered\", \"called upon\", \"reminded\", \"urged\", \"asked\", \"persuaded\", \"convinced\", \"forced\", \"pushed\"]\n",
    "verbs = [\"promised\"]\n",
    "actions = [(\"to leave\", \"left\"), (\"to call home\", \"called home\"), (\"to reply\", \"replied\"), (\"to wipe the counter\", \"wiped the counter\"), (\"to dance\", \"danced\")]\n",
    "correct_index = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 3\n",
    "For GPT3, inference is not deterministic, so we're running 5 replicants per prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpt_kwargs = {\"max_tokens\": 2, \"temperature\": 0.0}\n",
    "# gpt_subject_control_experiment  = Experiment(\"gpt3\", \"subject-control\", FixedGPTPrompt, run_gpt_prompt, 5, gpt_kwargs)\n",
    "\n",
    "# gpt_subject_control_experiment.run(names, correct_index, verbs, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_df = gpt_subject_control_experiment.format_results()\n",
    "\n",
    "# gpt_df.to_csv(\"/Users/Elias/child-lm/results/gpt_subject_control_swap_names.csv\")\n",
    "\n",
    "gpt_df = pd.read_csv(\"/Users/Elias/child-lm/results/gpt_subject_control_swap_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': (0.38, 50),\n",
       " 'acc_by_name': {'Tom,Mary': (0.3, 10),\n",
       "  'Tom,Bill': (0.5, 10),\n",
       "  'Mary,Bill': (0.7, 10),\n",
       "  'Morgan,Jaime': (0.4, 10),\n",
       "  'Ellen,Mary': (0.0, 10)},\n",
       " 'acc_by_action': {'to call home': (0.5, 10),\n",
       "  'to reply': (0.1, 10),\n",
       "  'to leave': (0.4, 10),\n",
       "  'to wipe the counter': (0.5, 10),\n",
       "  'to dance': (0.4, 10)},\n",
       " 'acc_by_verb': {'promised': (0.38, 50)},\n",
       " 'acc_by_action_by_verb': {'to call home,promised': (0.5, 10),\n",
       "  'to reply,promised': (0.1, 10),\n",
       "  'to leave,promised': (0.4, 10),\n",
       "  'to wipe the counter,promised': (0.5, 10),\n",
       "  'to dance,promised': (0.4, 10)}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_report(gpt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# t5_subject_control_experiment  = Experiment(\"t5\", \"subject-control\", FixedT5Prompt, run_t5_prompt, 1, None)\n",
    "\n",
    "# t5_subject_control_experiment.run(names, correct_index, verbs, actions, do_swap = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5_df = t5_subject_control_experiment.format_results()\n",
    "\n",
    "# t5_df.to_csv(\"/Users/Elias/child-lm/results/t5_subject_control.csv\")\n",
    "\n",
    "t5_df = pd.read_csv(\"/Users/Elias/child-lm/results/t5_subject_control.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': (0.08, 25),\n",
       " 'acc_by_name': {'Tom,Mary': (0.0, 5),\n",
       "  'Tom,Bill': (0.0, 5),\n",
       "  'Mary,Bill': (0.0, 5),\n",
       "  'Morgan,Jaime': (0.4, 5),\n",
       "  'Ellen,Mary': (0.0, 5)},\n",
       " 'acc_by_action': {'to call home': (0.2, 5),\n",
       "  'to reply': (0.0, 5),\n",
       "  'to leave': (0.0, 5),\n",
       "  'to wipe the counter': (0.2, 5),\n",
       "  'to dance': (0.0, 5)},\n",
       " 'acc_by_verb': {'promised': (0.08, 25)},\n",
       " 'acc_by_action_by_verb': {'to call home,promised': (0.2, 5),\n",
       "  'to reply,promised': (0.0, 5),\n",
       "  'to leave,promised': (0.0, 5),\n",
       "  'to wipe the counter,promised': (0.2, 5),\n",
       "  'to dance,promised': (0.0, 5)}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_report(t5_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jurassic Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# jurassic_kwargs = {\"maxTokens\": 2, \"temperature\": 0.0}\n",
    "# jurassic_subject_control_experiment  = Experiment(\"jurassic-large\", \"subject-control\", FixedGPTPrompt, run_ai21_prompt, 1, jurassic_kwargs)\n",
    "\n",
    "# jurassic_subject_control_experiment.run(names, correct_index, verbs, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jurassic_df = jurassic_subject_control_experiment.format_results()\n",
    "\n",
    "# jurassic_df.to_csv(\"/Users/Elias/child-lm/results/jurassic_subject_control_swap_names.csv\")\n",
    "\n",
    "jurassic_df = pd.read_csv(\"/Users/Elias/child-lm/results/jurassic_subject_control_swap_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': (0.84, 50),\n",
       " 'acc_by_name': {'Tom,Mary': (0.9, 10),\n",
       "  'Tom,Bill': (0.9, 10),\n",
       "  'Mary,Bill': (0.5, 10),\n",
       "  'Morgan,Jaime': (1.0, 10),\n",
       "  'Ellen,Mary': (0.9, 10)},\n",
       " 'acc_by_action': {'to call home': (0.9, 10),\n",
       "  'to reply': (0.9, 10),\n",
       "  'to leave': (0.7, 10),\n",
       "  'to wipe the counter': (0.8, 10),\n",
       "  'to dance': (0.9, 10)},\n",
       " 'acc_by_verb': {'promised': (0.84, 50)},\n",
       " 'acc_by_action_by_verb': {'to call home,promised': (0.9, 10),\n",
       "  'to reply,promised': (0.9, 10),\n",
       "  'to leave,promised': (0.7, 10),\n",
       "  'to wipe the counter,promised': (0.8, 10),\n",
       "  'to dance,promised': (0.9, 10)}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_report(jurassic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Coerced examples with gender\n",
    "\n",
    "By using gendered names and pronouns, we can coerce subject or object control from \"suggested\", \"offered\", and \"proposed\", e.g. \n",
    "\n",
    "- Mary proposed to Tom to be his editor\n",
    "- Tom suggested to Mary to be her editor \n",
    "- Mary offered to Tom to be his editor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = [\"promised\", \"offered\", \"suggested\", \"proposed\"]\n",
    "his_names = [(\"Tom\", \"Mary\"), (\"Bill\", \"Mary\"), (\"James\", \"Mary\"), (\"Tom\", \"Sally\"), (\"Bill\", \"Sally\"), (\"James\", \"Sally\")]\n",
    "actions = [(\"to be her editor\", \"was the editor\")]\n",
    "correct_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpt_kwargs = {\"max_tokens\": 2, \"temperature\": 0.0}\n",
    "# gendered_gpt_subject_control_experiment  = Experiment(\"gpt3\", \"subject-control\", FixedGPTPrompt, run_gpt_prompt, 5, gpt_kwargs)\n",
    "# gendered_gpt_subject_control_experiment.run(his_names, correct_index, verbs, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gendered_gpt_df = gendered_gpt_subject_control_experiment.format_results()\n",
    "\n",
    "# gendered_gpt_df.to_csv(\"/Users/Elias/child-lm/results/gpt_gendered_subject_control_swap_names.csv\")\n",
    "gendered_gpt_df = pd.read_csv(\"/Users/Elias/child-lm/results/gpt_gendered_subject_control_swap_names.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': (0.3125, 48),\n",
       " 'acc_by_name': {'James,Sally': (0.5, 8),\n",
       "  'James,Mary': (0.0, 8),\n",
       "  'Tom,Sally': (0.625, 8),\n",
       "  'Tom,Mary': (0.125, 8),\n",
       "  'Bill,Sally': (0.625, 8),\n",
       "  'Bill,Mary': (0.0, 8)},\n",
       " 'acc_by_action': {'to be her editor': (0.3125, 48)},\n",
       " 'acc_by_verb': {'promised': (0.4166666666666667, 12),\n",
       "  'suggested': (0.25, 12),\n",
       "  'proposed': (0.3333333333333333, 12),\n",
       "  'offered': (0.25, 12)},\n",
       " 'acc_by_action_by_verb': {'to be her editor,promised': (0.4166666666666667,\n",
       "   12),\n",
       "  'to be her editor,suggested': (0.25, 12),\n",
       "  'to be her editor,proposed': (0.3333333333333333, 12),\n",
       "  'to be her editor,offered': (0.25, 12)}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_report(gendered_gpt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 for QA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gendered_t5_subject_control_experiment  = Experiment(\"t5\", \"subject-control\", FixedT5Prompt, run_t5_prompt, 1, None)\n",
    "# gendered_t5_subject_control_experiment.run(his_names, correct_index, verbs, actions)\n",
    "# gendered_t5_df = gendered_t5_subject_control_experiment.format_results()\n",
    "# gendered_t5_df.to_csv(\"/Users/Elias/child-lm/results/t5_gendered_subject_control_swap_names.csv\")\n",
    "gendered_t5_df = pd.read_csv(\"/Users/Elias/child-lm/results/t5_gendered_subject_control_swap_names.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': (0.0, 48),\n",
       " 'acc_by_name': {'James,Sally': (0.0, 8),\n",
       "  'James,Mary': (0.0, 8),\n",
       "  'Tom,Sally': (0.0, 8),\n",
       "  'Tom,Mary': (0.0, 8),\n",
       "  'Bill,Sally': (0.0, 8),\n",
       "  'Bill,Mary': (0.0, 8)},\n",
       " 'acc_by_action': {'to be her editor': (0.0, 48)},\n",
       " 'acc_by_verb': {'promised': (0.0, 12),\n",
       "  'suggested': (0.0, 12),\n",
       "  'proposed': (0.0, 12),\n",
       "  'offered': (0.0, 12)},\n",
       " 'acc_by_action_by_verb': {'to be her editor,promised': (0.0, 12),\n",
       "  'to be her editor,suggested': (0.0, 12),\n",
       "  'to be her editor,proposed': (0.0, 12),\n",
       "  'to be her editor,offered': (0.0, 12)}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_report(gendered_t5_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jurassic Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jurassic_kwargs = {\"maxTokens\": 2, \"temperature\": 0.0}\n",
    "# gendered_jurassic_subject_control_experiment  = Experiment(\"jurassic\", \"subject-control\", FixedGPTPrompt, run_ai21_prompt, 1, jurassic_kwargs)\n",
    "# gendered_jurassic_subject_control_experiment.run(his_names, correct_index, verbs, actions)\n",
    "# gendered_jurassic_df = gendered_jurassic_subject_control_experiment.format_results()\n",
    "# gendered_jurassic_df.to_csv(\"/Users/Elias/child-lm/results/jurassic_gendered_subject_control_swap_names.csv\")\n",
    "gendered_jurassic_df = pd.read_csv(\"/Users/Elias/child-lm/results/jurassic_gendered_subject_control_swap_names.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': (0.6875, 48),\n",
       " 'acc_by_name': {'James,Sally': (1.0, 8),\n",
       "  'James,Mary': (0.625, 8),\n",
       "  'Tom,Sally': (0.875, 8),\n",
       "  'Tom,Mary': (0.625, 8),\n",
       "  'Bill,Sally': (0.5, 8),\n",
       "  'Bill,Mary': (0.5, 8)},\n",
       " 'acc_by_action': {'to be her editor': (0.6875, 48)},\n",
       " 'acc_by_verb': {'promised': (0.8333333333333334, 12),\n",
       "  'suggested': (0.5833333333333334, 12),\n",
       "  'proposed': (0.6666666666666666, 12),\n",
       "  'offered': (0.6666666666666666, 12)},\n",
       " 'acc_by_action_by_verb': {'to be her editor,promised': (0.8333333333333334,\n",
       "   12),\n",
       "  'to be her editor,suggested': (0.5833333333333334, 12),\n",
       "  'to be her editor,proposed': (0.6666666666666666, 12),\n",
       "  'to be her editor,offered': (0.6666666666666666, 12)}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy_report(gendered_jurassic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passives \n",
    "\n",
    "Do passives here make sense? To me \n",
    "- Mary was promised by Tom to leave\n",
    "Does not sound acceptable, or if it is accepetable, Mary is the one leaving, unlike \"Tom promised Mary to leave\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec6008f546f3cd66431ed7a4f2e2b63949ea9a2fd324a00b9368fd8a5a5333f5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('openai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
