{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "\n",
    "from metrics import accuracy_report\n",
    "import re \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def get_variance(csv_groups, level, filtered = False):\n",
    "    # consolidate data from different csvs \n",
    "    all_dfs = {g:[] for g in csv_groups.keys()}\n",
    "    for group, csvs in csv_groups.items():\n",
    "        for csv in csvs:\n",
    "            df = pd.read_csv(csv)\n",
    "            # print(csv, len(df))\n",
    "            all_dfs[group].append(df)\n",
    "\n",
    "    reports = {g: [accuracy_report(df) for df in dfs] for g, dfs in all_dfs.items()}\n",
    "    # data = [report[level] for report in reports]\n",
    "    data = {g: [report[level] for report in group_reports] for g, group_reports in reports.items()}\n",
    "    \n",
    "    to_ret = {g: defaultdict(int)  for g in data.keys()}\n",
    "    for group, group_data in data.items():\n",
    "        for i, data_dict in enumerate(group_data):\n",
    "            df = all_dfs[group][i]\n",
    "            model_name = df['model'][0]\n",
    "            model_name = re.sub(\"_\", \"-\", model_name)\n",
    "            model_name = re.sub(\"-qa\", \"\", model_name)\n",
    "            df_to_analyze = pd.DataFrame(columns=[\"model\", \"acc\", \"type\", \"group\"], dtype=object)\n",
    "            for k, v in data_dict.items():\n",
    "                if filtered: \n",
    "                    acc = float(v[2])\n",
    "                else:\n",
    "                    acc = float(v[0])\n",
    "                type_name = k\n",
    "                df_to_analyze = df_to_analyze.append({\"model\": model_name, \"acc\": acc, \"type\": type_name, \"group\": group}, ignore_index=True)\n",
    "        \n",
    "            to_ret[group][model_name] = df_to_analyze.var()['acc']\n",
    "\n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_by_swap: {'Object control': 0.06685474999999999, 'Passive object control': 0.0536631388888889, 'Subject control': 0.06750555555555554}\n",
      "acc_by_name: {'Object control': 0.002499047619047619, 'Passive object control': 0.0067037500000000005, 'Subject control': 0.010133928571428572}\n",
      "acc_by_action: {'Object control': 0.0011700694444444445, 'Passive object control': 0.010889965277777776, 'Subject control': 0.005052083333333334}\n",
      "acc_by_verb: {'Object control': 0.002184429012345679, 'Passive object control': 0.0030200154320987648, 'Subject control': nan}\n"
     ]
    }
   ],
   "source": [
    "oc_csvs=[\"../results_to_plot/gpt_object_control_swap_names.csv\", \n",
    "     \"../results_to_plot/gpt_neo_1.3B_object_control.csv\", \n",
    "     \"../results_to_plot/gpt_neo_2.7b_object_control.csv\", \n",
    "     \"../results_to_plot/gpt_j_object_control.csv\", \n",
    "     \"../results_to_plot/jurassic_object_control_swap_names.csv\", \n",
    "     \"../results_to_plot/jurassic_jumbo_object_control_swap_names.csv\", \n",
    "     \"../results_to_plot/t5_object_control.csv\",\n",
    "     \"../results_to_plot/t0_object_control.csv\"]\n",
    "\n",
    "sc_csvs=[\"../results_to_plot/gpt_subject_control_swap_names.csv\", \n",
    "     \"../results_to_plot/gpt_neo_1.3B_subject_control.csv\",\n",
    "     \"../results_to_plot/gpt_neo_2.7b_subject_control.csv\", \n",
    "     \"../results_to_plot/gpt_j_subject_control.csv\",\n",
    "     \"../results_to_plot/jurassic_subject_control_swap_names.csv\", \n",
    "     \"../results_to_plot/jurassic_jumbo_subject_control_swap_names.csv\", \n",
    "     \"../results_to_plot/t5_subject_control.csv\",\n",
    "     \"../results_to_plot/t0_subject_control.csv\"]\n",
    "\n",
    "poc_csvs=[\"../results_to_plot/gpt_passive_object_control_swap_names.csv\", \n",
    "     \"../results_to_plot/gpt_neo_1.3B_passive_object_control.csv\",\n",
    "     \"../results_to_plot/gpt_neo_2.7b_passive_object_control.csv\",\n",
    "     \"../results_to_plot/gpt_j_passive_object_control.csv\",\n",
    "     \"../results_to_plot/jurassic_passive_object_control_swap_names.csv\", \n",
    "     \"../results_to_plot/jurassic_jumbo_passive_object_control_swap_names.csv\", \n",
    "     \"../results_to_plot/t5_passive_object_control.csv\",\n",
    "     \"../results_to_plot/t0_passive_object_control.csv\"]\n",
    "\n",
    "\n",
    "\n",
    "csv_data = {\"Object control\": oc_csvs, \"Passive object control\": poc_csvs, \"Subject control\": sc_csvs}\n",
    "\n",
    "\n",
    "for level in ['acc_by_swap', 'acc_by_name', \"acc_by_action\", \"acc_by_verb\"]:\n",
    "    variance_data = get_variance(csv_data, level=level, filtered=False)\n",
    "    variance_data_mean = {k: np.mean(list(v.values())) for k,v in variance_data.items()}\n",
    "    print(f\"{level}: {variance_data_mean}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_by_swap: {'Object control': 0.07073724462778007, 'Passive object control': 0.061759194170686885, 'Subject control': 0.07132172003035728}\n",
      "acc_by_name: {'Object control': 0.002513778679560443, 'Passive object control': 0.011377208968828286, 'Subject control': 0.010127446780419654}\n",
      "acc_by_action: {'Object control': 0.0011487795916267233, 'Passive object control': 0.0035076140595954957, 'Subject control': 0.004831895679918914}\n",
      "acc_by_verb: {'Object control': 0.002193370506556329, 'Passive object control': 0.002259124793038023, 'Subject control': nan}\n"
     ]
    }
   ],
   "source": [
    "for level in ['acc_by_swap', 'acc_by_name', \"acc_by_action\", \"acc_by_verb\"]:\n",
    "    variance_data = get_variance(csv_data, level=level, filtered=True)\n",
    "    variance_data_mean = {k: np.mean(list(v.values())) for k,v in variance_data.items()}\n",
    "    print(f\"{level}: {variance_data_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "            \\toprule \n",
      "            Level & OC & SC & P-OC \\\\\n",
      "            \\midrule\n",
      "        \n",
      "swap names & 0.067/0.071  & 0.068/0.071 & 0.054/0.062 \\\\\n",
      "names & 0.002/0.003  & 0.010/0.010 & 0.007/0.011 \\\\\n",
      "action & 0.001/0.001  & 0.005/0.005 & 0.011/0.004 \\\\\n",
      "verb & 0.002/0.002  & nan/nan & 0.003/0.002 \\\\\n",
      "\\bottomrule\n",
      "        \\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make latex \n",
    "levels = ['acc_by_swap', 'acc_by_name', \"acc_by_action\", \"acc_by_verb\"]\n",
    "level_lookup = {\"acc_by_swap\": \"swap names\", \n",
    "                \"acc_by_name\": \"names\", \n",
    "                \"acc_by_action\": \"action\",\n",
    "                \"acc_by_verb\": \"verb\"}\n",
    "# df_for_table = pd.DataFrame(columns = ['Level', \"OC\", \"SC\", \"P-OC\"], dtype=object)\n",
    "\n",
    "header = \"\"\"\\\\begin{tabular}{llll}\n",
    "            \\\\toprule \n",
    "            Level & OC & SC & P-OC \\\\\\\\\n",
    "            \\\\midrule\n",
    "        \"\"\"\n",
    "print(header)\n",
    "for level in levels: \n",
    "    variance_data_no_filter = get_variance(csv_data, level=level, filtered=False)\n",
    "    variance_data_no_filter_mean = {k: np.mean(list(v.values())) for k,v in variance_data_no_filter.items()}\n",
    "    variance_data_filter = get_variance(csv_data, level=level, filtered=True)\n",
    "    variance_data_filter_mean = {k: np.mean(list(v.values())) for k,v in variance_data_filter.items()}\n",
    "\n",
    "    row = f\"{level_lookup[level]} & {variance_data_no_filter_mean['Object control']:.3f}/{variance_data_filter_mean['Object control']:.3f} \"\\\n",
    "        f\" & {variance_data_no_filter_mean['Subject control']:.3f}/{variance_data_filter_mean['Subject control']:.3f}\" \\\n",
    "        f\" & {variance_data_no_filter_mean['Passive object control']:.3f}/{variance_data_filter_mean['Passive object control']:.3f} \\\\\\\\\" \n",
    "    print(row)\n",
    "\n",
    "\n",
    "print(\"\"\"\\\\bottomrule\n",
    "        \\\\end{tabular}\"\"\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec6008f546f3cd66431ed7a4f2e2b63949ea9a2fd324a00b9368fd8a5a5333f5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('openai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
