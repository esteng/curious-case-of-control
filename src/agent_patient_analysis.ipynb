{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis import recompute_agent_patient, do_mcnemar \n",
    "import pathlib \n",
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from agent_patient_experiment import AgentPatientExperiment\n",
    "np.random.seed(12)\n",
    "path_to_file = pathlib.Path(\"\").absolute()\n",
    "parent = path_to_file.parent\n",
    "\n",
    "\n",
    "def get_df(condition, is_two = False, thresh=30):\n",
    "    cos_df = pd.DataFrame(columns=[\"model\", \"num_prompts\", \"accuracy\", \"num_valid\"], dtype=object)\n",
    "    if is_two:\n",
    "        two_affix = \"_2\"\n",
    "    else:\n",
    "        two_affix = \"_1\"\n",
    "    for prefix in range(0,4):\n",
    "        \n",
    "        change_of_state_csvs = [parent.joinpath(f'agent_patient_results{two_affix}/gpt_{condition}_prefix_{prefix}.csv'),\n",
    "                                parent.joinpath(f'agent_patient_results{two_affix}/gpt_neo_1.3b_{condition}{two_affix}_prefix_{prefix}.csv'),\n",
    "                                parent.joinpath(f'agent_patient_results{two_affix}/gpt_neo_2.7b_{condition}{two_affix}_prefix_{prefix}.csv'),\n",
    "                                parent.joinpath(f'agent_patient_results{two_affix}/gpt_j_{condition}{two_affix}_prefix_{prefix}.csv'),\n",
    "                                parent.joinpath(f'agent_patient_results{two_affix}/jurassic_{condition}_prefix_{prefix}.csv'),\n",
    "                                parent.joinpath(f'agent_patient_results{two_affix}/jurassic_jumbo_{condition}_prefix_{prefix}.csv'),\n",
    "                                # parent.joinpath(f'agent_patient_results{two_affix}/t5_{condition}{two_affix}_prefix_{prefix}.csv'),\n",
    "                                parent.joinpath(f'agent_patient_results{two_affix}/t0_{condition}{two_affix}_prefix_{prefix}.csv') ]\n",
    "        names = [\"gpt\", \"gpt-neo-1.3b\", \"gpt-neo-2.7b\", \"gpt-j\", \"jurassic-large\", \"jurassic-jumbo\", \"t0\"]\n",
    "        prompt_files = [parent.joinpath(f\"data/agent_patient/{condition}{two_affix}_prefix_{prefix}.json\") for i in range(len(change_of_state_csvs))]\n",
    "        cos_acc = recompute_agent_patient(change_of_state_csvs, prompt_files, names)\n",
    "\n",
    "        for model in names:\n",
    "            try:\n",
    "                __, __, acc, num = cos_acc[model]\n",
    "            except KeyError:\n",
    "                acc, num = -1.0, 0\n",
    "            if model in cos_df['model'].values:\n",
    "                curr_acc = cos_df[cos_df['model'] == model]['accuracy'].values[0]\n",
    "                curr_num = cos_df[cos_df['model'] == model]['num_valid'].values[0]\n",
    "\n",
    "                curr_weighted = curr_acc * curr_num\n",
    "                if num > thresh:\n",
    "                    # if acc > curr_acc:\n",
    "                    weighted = acc * num\n",
    "                    if weighted > curr_weighted:\n",
    "                        cos_df.loc[cos_df['model'] == model, 'num_prompts'] = prefix\n",
    "                        cos_df.loc[cos_df['model'] == model, 'accuracy'] = acc\n",
    "                        cos_df.loc[cos_df['model'] == model, 'num_valid'] = num \n",
    "            else:\n",
    "                if num > thresh: \n",
    "                    cos_df = cos_df.append({\"model\": model, \"num_prompts\": prefix, \"accuracy\": acc, \"num_valid\": num}, ignore_index=True)\n",
    "                else:\n",
    "                    cos_df = cos_df.append({\"model\": model, \"num_prompts\": prefix, \"accuracy\": -1.0, \"num_valid\": 0}, ignore_index=True)\n",
    "        # print(prefix, cos_acc)\n",
    "    # print(cos_df)\n",
    "    return cos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gpt', 1, 1, 'gpt_neo_2.7b', 0, 2, 0.6101694915254238, 0.45454545454545453, 0.011351591436778108, 14.0)\n",
      "('gpt', 1, 1, 't0', 0, 1, 0.6101694915254238, 0.4661016949152542, 0.03961701489849968, 22.0)\n",
      "('gpt', 1, 1, 't0', 3, 1, 0.6101694915254238, 0.4576271186440678, 0.0327657590988232, 23.0)\n",
      "('gpt', 1, 2, 'gpt_neo_2.7b', 0, 2, 0.6101694915254238, 0.45454545454545453, 0.011351591436778108, 14.0)\n",
      "('gpt', 1, 2, 't0', 0, 1, 0.6101694915254238, 0.4661016949152542, 0.03961701489849968, 22.0)\n",
      "('gpt', 1, 2, 't0', 3, 1, 0.6101694915254238, 0.4576271186440678, 0.0327657590988232, 23.0)\n",
      "('gpt', 2, 2, 'random', 0, 0, 0.5726495726495726, 0.3983050847457627, 0.011928139715763179, 19.0)\n",
      "('gpt', 3, 1, 'gpt_neo_1.3b', 2, 2, 0.5862068965517241, 0.49382716049382713, 0.03355243967962451, 12.0)\n",
      "('gpt', 3, 1, 'gpt_neo_1.3b', 3, 2, 0.5862068965517241, 0.4307692307692308, 0.0241195447742939, 8.0)\n",
      "('gpt', 3, 1, 'jurassic_jumbo', 1, 1, 0.5862068965517241, 0.4835164835164835, 0.010673840530216694, 8.0)\n",
      "('gpt', 3, 1, 'jurassic_jumbo', 1, 2, 0.5862068965517241, 0.4835164835164835, 0.010673840530216694, 8.0)\n",
      "('gpt', 3, 2, 'gpt_neo_1.3b', 2, 2, 0.5862068965517241, 0.49382716049382713, 0.03355243967962451, 12.0)\n",
      "('gpt', 3, 2, 'gpt_neo_1.3b', 3, 2, 0.5862068965517241, 0.4307692307692308, 0.0241195447742939, 8.0)\n",
      "('gpt', 3, 2, 'jurassic_jumbo', 1, 1, 0.5862068965517241, 0.4835164835164835, 0.010673840530216694, 8.0)\n",
      "('gpt', 3, 2, 'jurassic_jumbo', 1, 2, 0.5862068965517241, 0.4835164835164835, 0.010673840530216694, 8.0)\n",
      "('gpt_neo_1.3b', 0, 1, 'jurassic', 0, 1, 0.6226415094339622, 0.5412844036697247, 0.03569813817739487, 8.0)\n",
      "('gpt_neo_1.3b', 0, 1, 'jurassic', 0, 2, 0.6226415094339622, 0.5412844036697247, 0.03569813817739487, 8.0)\n",
      "('gpt_neo_1.3b', 3, 2, 't0', 0, 2, 0.4307692307692308, 0.5338983050847458, 0.028816719655878845, 11.0)\n"
     ]
    }
   ],
   "source": [
    "# if False: \n",
    "# print(f\"change of state\")\n",
    "# cos_df1 = get_df(\"change_of_state\")\n",
    "# print(cos_df1)\n",
    "# cos_df2 = get_df(\"change_of_state\", is_two=True)\n",
    "# print(cos_df2)\n",
    "\n",
    "\n",
    "# models_levels_prefixes = [(\"gpt\", 3, 2), \n",
    "#                           (\"gpt_neo_1.3b\", 2, 2), \n",
    "#                           (\"gpt_neo_2.7b\", 0, 2), \n",
    "#                           (\"gpt_j\", 0, 2), \n",
    "#                           (\"jurassic\", 1, 2), \n",
    "#                           (\"jurassic_jumbo\", 1, 1), \n",
    "#                           (\"t0\", 1, 2),\n",
    "#                           (\"random\", 0,0)]\n",
    "\n",
    "models_levels_prefixes = []\n",
    "for model in [\"gpt\", \"gpt_neo_1.3b\", \"gpt_neo_2.7b\", \"gpt_j\", \"jurassic\", \"jurassic_jumbo\", \"t0\"]: \n",
    "    for level in range(4): \n",
    "        for aff in [1,2]: \n",
    "            models_levels_prefixes.append((model, level, aff))\n",
    "\n",
    "models_levels_prefixes.append((\"random\", 0, 0))\n",
    "\n",
    "results = []\n",
    "done = []\n",
    "for model1, level1, two_affix1 in models_levels_prefixes: \n",
    "    for model2, level2, two_affix2 in models_levels_prefixes: \n",
    "        if model1 == model2 or ((model1, model2, level1, level2, two_affix1, two_affix2) in done) or ((model2,model1, level2, level1, two_affix2, two_affix1) in done): \n",
    "            continue\n",
    "        pval, stat, table = do_mcnemar(model1, model2, level1, level2, f\"_{two_affix1}\", f\"_{two_affix2}\", condition=\"change_of_state\")\n",
    "        model1_acc = len(table[model1]['correct'])/(len(table[model1]['correct']) + len(table[model1]['incorrect']))\n",
    "        model2_acc = len(table[model2]['correct'])/(len(table[model2]['correct']) + len(table[model2]['incorrect']))\n",
    "        results.append((model1, level1, two_affix1, model2, level2, two_affix2, model1_acc, model2_acc, pval, stat))  \n",
    "        done.append((model1, model2, level1, level2, two_affix1, two_affix2))\n",
    "\n",
    "for x in results:\n",
    "    if x[-2] < 0.05 and x[-1] > 5:\n",
    "        print(x)\n",
    "# [print(x) for x in results]\n",
    "# for level in range(3):\n",
    "#     for model in [\"gpt\", \"gpt-neo-1.3b\", \"gpt-neo-2.7b\", \"gpt-j\", \"jurassic-large\", \"jurassic-jumbo\", \"t0\"]\n",
    "\n",
    "\n",
    "# do_mcnemar(\"gpt_neo_1.3b\", \"gpt_neo_1.3b\", \"0\", \"0\", \"_1\", \"_1\", \"change_of_state\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_66537/3623479340.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mpval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_mcnemar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"_{two_affix1}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"_{two_affix2}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"volition\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mmodel1_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'correct'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'correct'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'incorrect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mmodel2_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'correct'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'correct'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'incorrect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwo_affix1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwo_affix2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel1_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwo_affix1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwo_affix2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# if False:\n",
    "# print(f\"volition\")\n",
    "# vol_df1 = get_df(\"volition\")\n",
    "# print(vol_df1)\n",
    "# vol_df2 = get_df(\"volition\", is_two=True)\n",
    "# print(vol_df2)\n",
    "\n",
    "# models_levels_prefixes = [(\"gpt\", 3, 2), \n",
    "#                         #   (\"gpt_neo_1.3b\", 2, 2), \n",
    "#                           (\"gpt_neo_2.7b\", 1, 1), \n",
    "#                           (\"gpt_j\", 0, 1), \n",
    "#                           (\"jurassic\", 2, 1), \n",
    "#                           (\"jurassic_jumbo\", 2, 1), \n",
    "#                           (\"t0\", 0, 1),\n",
    "#                           (\"random\", 0, 0)]\n",
    "\n",
    "\n",
    "models_levels_prefixes = []\n",
    "for model in [\"gpt\", \"gpt_neo_1.3b\", \"gpt_neo_2.7b\", \"gpt_j\", \"jurassic\", \"jurassic_jumbo\", \"t0\"]: \n",
    "    for level in range(4): \n",
    "        for aff in [1,2]: \n",
    "            models_levels_prefixes.append((model, level, aff))\n",
    "\n",
    "models_levels_prefixes.append((\"random\", 0, 0))\n",
    "\n",
    "results = []\n",
    "done = []\n",
    "for model1, level1, two_affix1 in models_levels_prefixes: \n",
    "    for model2, level2, two_affix2 in models_levels_prefixes: \n",
    "        if model1 == model2 or ((model1, model2, level1, level2, two_affix1, two_affix2) in done) or ((model2,model1, level2, level1, two_affix2, two_affix1) in done): \n",
    "            continue\n",
    "        pval, stat, table = do_mcnemar(model1, model2, level1, level2, f\"_{two_affix1}\", f\"_{two_affix2}\", condition=\"volition\")\n",
    "        model1_acc = len(table[model1]['correct'])/(len(table[model1]['correct']) + len(table[model1]['incorrect']))\n",
    "\n",
    "        model2_acc = len(table[model2]['correct'])/(len(table[model2]['correct']) + len(table[model2]['incorrect']))\n",
    "        results.append((model1, level1, two_affix1, model2, level2, two_affix2, model1_acc, model2_acc, pval, stat))  \n",
    "        done.append((model1, model2, level1, level2, two_affix1, two_affix2))\n",
    "\n",
    "\n",
    "for x in results:\n",
    "    if x[-2] < 0.05 and x[-1] > 5:\n",
    "        print(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval, stat, table = do_mcnemar(\"gpt\", model2, level1, level2, f\"_{two_affix1}\", f\"_{two_affix2}\", condition=\"volition\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpt-neo-1.3b': (0.07, 100, 0.6363636363636364, 11)}\n"
     ]
    }
   ],
   "source": [
    "from vis import recompute_agent_patient \n",
    "import pathlib \n",
    "import os \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "path_to_file = pathlib.Path(\"\").absolute()\n",
    "parent = path_to_file.parent\n",
    "\n",
    "change_of_state_csvs = [parent.joinpath(f'agent_patient_results_1/gpt_neo_1.3b_volition_1_prefix_1.csv')]\n",
    "cos_acc = recompute_agent_patient(change_of_state_csvs, [parent.joinpath(f\"data/agent_patient/volition_1_prefix_1.json\")], ['gpt-neo-1.3b'])\n",
    "print(cos_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec6008f546f3cd66431ed7a4f2e2b63949ea9a2fd324a00b9368fd8a5a5333f5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('openai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
