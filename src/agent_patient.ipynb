{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recasting\n",
    "\n",
    "- This time, with and without prompting \n",
    "- Instructions: \n",
    "    - Please answer the following yes-no question about this sentence: <Sentence>\n",
    "- Volition: \n",
    "    - ``In the event \"<event>\", did the <arg> act on purpose?``\n",
    "    - Need to edit events and args to make grammatical \n",
    "- Change of state\n",
    "    - ``In the event \"<event>\", did the state of <arg> change?``\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decomp import UDSCorpus \n",
    "\n",
    "\n",
    "c = UDSCorpus(split='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from tqdm import tqdm \n",
    "volition_examples = []\n",
    "change_of_state_examples = []\n",
    "\n",
    "\n",
    "def extract_prompt_info(graph, edge): \n",
    "    pred_node, arg_node = edge \n",
    "    try:\n",
    "        pred = graph.head(pred_node)[1][0]\n",
    "        arg = graph.head(arg_node)[1][0]\n",
    "    except IndexError:\n",
    "        pred, arg = None, None\n",
    "    return pred, arg\n",
    "\n",
    "for gname in tqdm(c): \n",
    "    g = c[gname]\n",
    "    sent = g.sentence\n",
    "    try:\n",
    "        subg = g.semantics_subgraph\n",
    "    except AttributeError:\n",
    "        continue\n",
    "    if len(subg.nodes) == 0:\n",
    "        continue\n",
    "    for edge in subg.edges: \n",
    "        n1, n2 = edge \n",
    "\n",
    "        edge_props = subg.edges[edge]\n",
    "        if \"protoroles\" in edge_props: \n",
    "            if \"volition\" in edge_props['protoroles'] and abs(edge_props['protoroles']['volition']['value']) > 1: \n",
    "                pred, arg = extract_prompt_info(g, edge)\n",
    "                volition_example = (gname, edge, pred, arg, sent, edge_props['protoroles']['volition'])\n",
    "                volition_examples.append(volition_example)\n",
    "                \n",
    "            if \"change_of_state\" in edge_props['protoroles'] and abs(edge_props['protoroles']['change_of_state']['value']) > 1: \n",
    "                pred, arg = extract_prompt_info(g, edge)\n",
    "                change_of_state_example = (gname, edge, pred, arg, sent, edge_props['protoroles']['change_of_state'])\n",
    "                change_of_state_examples.append(change_of_state_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VolitionTemplate:\n",
    "    def __init__(self, sent, pred, arg, value=None): \n",
    "        self.sent = sent \n",
    "        self.pred = pred    \n",
    "        self.arg = arg\n",
    "        self.value = value \n",
    "\n",
    "    def __str__(self):\n",
    "        to_ret = f\"Sentence: \\\"{self.sent}\\\"\\n\" + \\\n",
    "                 f\"In the event \\\"{self.pred}\\\", does the participant \\\"{self.arg}\\\" act with volition?\" \n",
    "        if self.value is not None:\n",
    "            if self.value > 0: \n",
    "                ans = \"Yes\" \n",
    "            else:\n",
    "                ans = \"No\"\n",
    "            to_ret += f\"\\n{ans}\" \n",
    "        return to_ret \n",
    "\n",
    "class ChangeOfStateTemplate:\n",
    "    def __init__(self, sent, pred, arg, value=None): \n",
    "        self.sent = sent \n",
    "        self.pred = pred    \n",
    "        self.arg = arg\n",
    "        self.value = value\n",
    "\n",
    "    def __str__(self):\n",
    "        to_ret = f\"Sentence: \\\"{self.sent}\\\"\\n\" + \\\n",
    "                   f\"In the event \\\"{self.pred}\\\", does the state of the participant \\\"{self.arg}\\\" change?\" \n",
    "        if self.value is not None: \n",
    "            if self.value > 0: \n",
    "                ans = \"Yes\" \n",
    "            else:\n",
    "                ans = \"No\"\n",
    "            to_ret += f\"\\n{ans}\" \n",
    "        return to_ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# limit sentences to 35 tokens to avoid overly complicated ones \n",
    "max_len = 35\n",
    "\n",
    "volition_templates = []\n",
    "change_of_state_templates = []\n",
    "for example in volition_examples:\n",
    "    gname, edge, pred, arg, sent, val_dict = example\n",
    "    if len(re.split(\"\\s+\", sent)) > max_len:\n",
    "        continue\n",
    "    t = VolitionTemplate(sent, pred, arg, val_dict['value'])\n",
    "    volition_templates.append(t)\n",
    "\n",
    "for example in change_of_state_examples:\n",
    "    gname, edge, pred, arg, sent, val_dict = example\n",
    "    if len(re.split(\"\\s+\", sent)) > max_len:\n",
    "        continue\n",
    "    t = ChangeOfStateTemplate(sent, pred, arg, val_dict['value'])\n",
    "    change_of_state_templates.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "np.random.shuffle(volition_templates)\n",
    "np.random.shuffle(change_of_state_templates)\n",
    "\n",
    "# subset to balance yes and no \n",
    "yes_volition_templates = [x for x in volition_templates if x.value > 0]\n",
    "no_volition_templates = [x for x in volition_templates if x.value < 0]\n",
    "\n",
    "yes_cos_templates = [x for x in change_of_state_templates if x.value > 0]\n",
    "no_cos_templates = [x for x in change_of_state_templates if x.value < 0]\n",
    "\n",
    "min_volition = min(len(yes_volition_templates), len(no_volition_templates))\n",
    "min_cos = min(len(yes_cos_templates), len(no_cos_templates))\n",
    "\n",
    "samp_yes_volition_templates = np.random.choice(yes_volition_templates, size=min_volition, replace=False).tolist()\n",
    "samp_no_volition_templates = np.random.choice(no_volition_templates, size=min_volition, replace=False).tolist()\n",
    "samp_yes_cos_templates = np.random.choice(yes_cos_templates, size=min_cos, replace=False).tolist()\n",
    "samp_no_cos_templates = np.random.choice(no_cos_templates, size=min_cos, replace=False).tolist() \n",
    "\n",
    "\n",
    "balanced_volition_templates = samp_yes_volition_templates + samp_no_volition_templates\n",
    "balanced_cos_templates = samp_yes_cos_templates + samp_no_cos_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb \n",
    "import copy \n",
    "\n",
    "instr_str = \"Answer this yes-no question about the following sentence.\\n\"\n",
    "def make_prompts(templates, num_prompts, prefix_size = 3, instructions = instr_str):\n",
    "    np.random.shuffle(templates)\n",
    "    prompts = []\n",
    "    max_num_prompts = min(num_prompts, int(len(templates)/(prefix_size + 1)))\n",
    "    for i in range(max_num_prompts): \n",
    "        template_idxs = [i for i in range(len(templates))]\n",
    "        if len(templates) < prefix_size + 1:\n",
    "            break\n",
    "        chosen_idxs = np.random.choice(template_idxs, size=prefix_size + 1, replace=False).tolist()\n",
    "        chosen = [copy.deepcopy(templates[i]) for i in chosen_idxs]\n",
    "        templates = [x for i, x in enumerate(templates) if i not in chosen_idxs]\n",
    "        # set last val to None so that it doesn't show \n",
    "        correct_value = \"Yes\" if chosen[-1].value > 0 else \"No\"\n",
    "       \n",
    "        chosen[-1].value = None\n",
    "        prompt = instructions + \"\\n\".join([str(t) for t in chosen])\n",
    "        to_write = {\"prompt\": prompt, \"correct_value\": correct_value}\n",
    "        prompts.append(to_write)\n",
    "    return prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "for s in range(0, 4): \n",
    "    volition_prompts = make_prompts(balanced_volition_templates, 40, prefix_size=s) \n",
    "    cos_prompts = make_prompts(balanced_cos_templates, 40, prefix_size=s) \n",
    "\n",
    "    with open(f\"../data/agent_patient/volition_prefix_{s}.json\", \"w\") as f1:\n",
    "        json.dump(volition_prompts, f1)\n",
    "    with open(f\"../data/agent_patient/change_of_state_prefix_{s}.json\", \"w\") as f1:\n",
    "        json.dump(cos_prompts, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large models on SPRL\n",
    "## GPT-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:02<00:00,  1.23s/it]\n",
      "100%|██████████| 100/100 [01:59<00:00,  1.20s/it]\n",
      "100%|██████████| 100/100 [02:01<00:00,  1.22s/it]\n",
      "100%|██████████| 100/100 [02:01<00:00,  1.22s/it]\n",
      "100%|██████████| 100/100 [02:04<00:00,  1.25s/it]\n",
      "100%|██████████| 100/100 [02:05<00:00,  1.25s/it]\n",
      "100%|██████████| 100/100 [02:07<00:00,  1.28s/it]\n",
      "100%|██████████| 100/100 [02:06<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "from agent_patient_experiment import AgentPatientExperiment\n",
    "from api_tools import run_gpt_prompt\n",
    "import time \n",
    "s = 0\n",
    "gpt_kwargs = {\"max_tokens\": 20, \"temperature\": 0.0}\n",
    "# gpt_object_control_experiment  = AgentPatientExperiment(\"gpt3\", \"object-control\", FixedGPTPrompt, run_gpt_prompt, 1, gpt_kwargs)\n",
    "for s in range(0, 4):\n",
    "    gpt_object_control_experiment  = AgentPatientExperiment(\"gpt-3\", \"volition\", f\"../data/agent_patient/volition_1_prefix_{s}.json\", run_gpt_prompt, 1, gpt_kwargs)\n",
    "    t0 = time.time()\n",
    "    gpt_object_control_experiment.run(overwrite=False)\n",
    "    gpt_df = gpt_object_control_experiment.format_results()\n",
    "    t1 = time.time()\n",
    "    gpt_df.to_csv(f\"../agent_patient_results_1/gpt_volition_prefix_{s}.csv\")\n",
    "    time.sleep(max(0, 60 - (t1 - t0)) + 10)\n",
    "\n",
    "for s in range(0, 4):\n",
    "    gpt_object_control_experiment  = AgentPatientExperiment(\"gpt-3\", \"change_of_state\", f\"../data/agent_patient/change_of_state_1_prefix_{s}.json\", run_gpt_prompt, 1, gpt_kwargs)\n",
    "    t0 = time.time()\n",
    "    gpt_object_control_experiment.run(overwrite=False)\n",
    "\n",
    "    gpt_df = gpt_object_control_experiment.format_results()\n",
    "    t1 = time.time()\n",
    "    gpt_df.to_csv(f\"../agent_patient_results_1/gpt_change_of_state_prefix_{s}.csv\")\n",
    "    time.sleep(60)\n",
    "    time.sleep(max(0, 60 - (t1 - t0)) + 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:15<00:00,  1.35s/it]\n",
      "100%|██████████| 100/100 [02:10<00:00,  1.31s/it]\n",
      "100%|██████████| 100/100 [02:19<00:00,  1.39s/it]\n",
      "100%|██████████| 100/100 [02:25<00:00,  1.45s/it]\n",
      "100%|██████████| 100/100 [02:15<00:00,  1.35s/it]\n",
      "100%|██████████| 100/100 [02:12<00:00,  1.33s/it]\n",
      "100%|██████████| 100/100 [02:04<00:00,  1.24s/it]\n",
      "100%|██████████| 100/100 [02:05<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "from agent_patient_experiment import AgentPatientExperiment\n",
    "from api_tools import run_gpt_prompt\n",
    "import time \n",
    "s = 0\n",
    "gpt_kwargs = {\"max_tokens\": 20, \"temperature\": 0.0}\n",
    "# gpt_object_control_experiment  = AgentPatientExperiment(\"gpt3\", \"object-control\", FixedGPTPrompt, run_gpt_prompt, 1, gpt_kwargs)\n",
    "for s in range(0, 4):\n",
    "    gpt_object_control_experiment  = AgentPatientExperiment(\"gpt-3\", \"volition\", f\"../data/agent_patient/volition_2_prefix_{s}.json\", run_gpt_prompt, 1, gpt_kwargs)\n",
    "    t0 = time.time()\n",
    "    gpt_object_control_experiment.run(overwrite=False)\n",
    "    gpt_df = gpt_object_control_experiment.format_results()\n",
    "    t1 = time.time()\n",
    "    elapsed = t1-t0\n",
    "    gpt_df.to_csv(f\"../agent_patient_results_2/gpt_volition_prefix_{s}.csv\")\n",
    "    time.sleep(max(0, 60 - elapsed + 10))\n",
    "\n",
    "for s in range(0, 4):\n",
    "    gpt_object_control_experiment  = AgentPatientExperiment(\"gpt-3\", \"volition\", f\"../data/agent_patient/change_of_state_2_prefix_{s}.json\", run_gpt_prompt, 1, gpt_kwargs)\n",
    "    t0 = time.time\n",
    "    gpt_object_control_experiment.run(overwrite=False)\n",
    "\n",
    "    gpt_df = gpt_object_control_experiment.format_results()\n",
    "    t1 = time.time()\n",
    "    elapsed = t1 - t0\n",
    "    gpt_df.to_csv(f\"../agent_patient_results_2/gpt_change_of_state_prefix_{s}.csv\")\n",
    "    time.sleep(max(0, 60 - elapsed + 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jurassic large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [02:22<00:00,  1.21s/it]\n",
      "100%|██████████| 118/118 [02:22<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from agent_patient_experiment import AgentPatientExperiment\n",
    "from api_tools import run_ai21_prompt\n",
    "import time\n",
    "jurassic_kwargs = {\"max_tokens\": 20, \"temperature\": 0.0}\n",
    "\n",
    "# for s in range(0, 4):\n",
    "#     jurassic_object_control_experiment  = AgentPatientExperiment(\"jurassic-large\", \"volition\", f\"../data/agent_patient/volition_1_prefix_{s}.json\", run_ai21_prompt, 1, jurassic_kwargs)\n",
    "#     t0 = time.time()\n",
    "#     jurassic_object_control_experiment.run(overwrite=False)\n",
    "#     jurassic_df = jurassic_object_control_experiment.format_results()\n",
    "#     t1 = time.time()\n",
    "#     elapsed = t1 - t0\n",
    "#     jurassic_df.to_csv(f\"../agent_patient_results_1/jurassic_volition_prefix_{s}.csv\")\n",
    "#     time.sleep(max(0, 60 - elapsed + 10))\n",
    " \n",
    "\n",
    "for s in range(2, 4):\n",
    "    jurassic_object_control_experiment  = AgentPatientExperiment(\"jurassic-large\", \"change_of_state\", f\"../data/agent_patient/change_of_state_1_prefix_{s}.json\", run_ai21_prompt, 1, jurassic_kwargs)\n",
    "    t0 = time.time()\n",
    "    jurassic_object_control_experiment.run(overwrite=False)\n",
    "    jurassic_df = jurassic_object_control_experiment.format_results()\n",
    "    t1 = time.time()\n",
    "    elapsed = t1 - t0\n",
    "    jurassic_df.to_csv(f\"../agent_patient_results_1/jurassic_change_of_state_prefix_{s}.csv\")\n",
    "    time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 55/118 [00:22<00:22,  2.84it/s]"
     ]
    }
   ],
   "source": [
    "from agent_patient_experiment import AgentPatientExperiment\n",
    "from api_tools import run_ai21_prompt\n",
    "import time\n",
    "jurassic_kwargs = {\"max_tokens\": 20, \"temperature\": 0.0}\n",
    "\n",
    "# for s in range(0, 4):\n",
    "#     jurassic_object_control_experiment  = AgentPatientExperiment(\"jurassic-large\", \"volition\", f\"../data/agent_patient/volition_2_prefix_{s}.json\", run_ai21_prompt, 1, jurassic_kwargs)\n",
    "#     t0 = time.time()\n",
    "#     jurassic_object_control_experiment.run(overwrite=False)\n",
    "\n",
    "#     jurassic_df = jurassic_object_control_experiment.format_results()\n",
    "#     t1 = time.time()\n",
    "#     elapsed = t1 - t0\n",
    "#     jurassic_df.to_csv(f\"../agent_patient_results_2/jurassic_volition_prefix_{s}.csv\")\n",
    "#     time.sleep(60)\n",
    " \n",
    "time.sleep(60)\n",
    "for s in range(2, 4):\n",
    "    jurassic_object_control_experiment  = AgentPatientExperiment(\"jurassic-large\", \"volition\", f\"../data/agent_patient/change_of_state_2_prefix_{s}.json\", run_ai21_prompt, 1, jurassic_kwargs)\n",
    "    t0 = time.time()\n",
    "    jurassic_object_control_experiment.run(overwrite=False)\n",
    "\n",
    "    jurassic_df = jurassic_object_control_experiment.format_results()\n",
    "    t1 = time.time()\n",
    "    elapsed = t1 - t0\n",
    "    jurassic_df.to_csv(f\"../agent_patient_results_2/jurassic_change_of_state_prefix_{s}.csv\")\n",
    "    time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jurassic jumbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n"
     ]
    }
   ],
   "source": [
    "from agent_patient_experiment import AgentPatientExperiment\n",
    "from api_tools import run_ai21_jumbo_prompt\n",
    "import time \n",
    "jurassic_kwargs = {\"max_tokens\": 20, \"temperature\": 0.0}\n",
    "\n",
    "for s in range(0, 4):\n",
    "    jurassic_object_control_experiment  = AgentPatientExperiment(\"jurassic-jumbo\", \"volition\", f\"../data/agent_patient/volition_1_prefix_{s}.json\", run_ai21_jumbo_prompt, 1, jurassic_kwargs)\n",
    "\n",
    "    t0 = time.time()\n",
    "    jurassic_object_control_experiment.run(overwrite=False, rate_limit_delay=60, rate_limit_count=19)\n",
    "    jurassic_df = jurassic_object_control_experiment.format_results()\n",
    "    t1 = time.time()\n",
    "    elapsed = t1-t0\n",
    "    jurassic_df.to_csv(f\"../agent_patient_results_1/jurassic_jumbo_volition_prefix_{s}.csv\")\n",
    "    time.sleep(max(0, 60 - elapsed + 10))\n",
    "\n",
    "for s in range(0, 4):\n",
    "    jurassic_object_control_experiment  = AgentPatientExperiment(\"jurassic-jumbo\", \"volition\", f\"../data/agent_patient/change_of_state_1_prefix_{s}.json\", run_ai21_jumbo_prompt, 1, jurassic_kwargs)\n",
    "    t0 = time.time()\n",
    "    jurassic_object_control_experiment.run(overwrite=False, rate_limit_delay=60, rate_limit_count=19)\n",
    "\n",
    "    jurassic_df = jurassic_object_control_experiment.format_results()\n",
    "    t1 = time.time()\n",
    "    elapsed = t1-t0\n",
    "    jurassic_df.to_csv(f\"../agent_patient_results_1/jurassic_jumbo_change_of_state_prefix_{s}.csv\")\n",
    "    time.sleep(max(0, 60 - elapsed + 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n"
     ]
    }
   ],
   "source": [
    "from agent_patient_experiment import AgentPatientExperiment\n",
    "from api_tools import run_ai21_jumbo_prompt\n",
    "import time \n",
    "jurassic_kwargs = {\"max_tokens\": 20, \"temperature\": 0.0}\n",
    "\n",
    "for s in range(0, 4):\n",
    "    jurassic_object_control_experiment  = AgentPatientExperiment(\"jurassic-jumbo\", \"volition\", f\"../data/agent_patient/volition_2_prefix_{s}.json\", run_ai21_jumbo_prompt, 1, jurassic_kwargs)\n",
    "    t0 = time.time\n",
    "    jurassic_object_control_experiment.run(overwrite=False, rate_limit_delay=60, rate_limit_count=19)\n",
    "\n",
    "    jurassic_df = jurassic_object_control_experiment.format_results()\n",
    "    t1 = time.time()\n",
    "    elapsed = t1-t0\n",
    "    jurassic_df.to_csv(f\"../agent_patient_results_2/jurassic_jumbo_volition_prefix_{s}.csv\")\n",
    "    time.sleep(max(0, 60 - elapsed + 10))\n",
    "\n",
    "for s in range(0, 4):\n",
    "    jurassic_object_control_experiment  = AgentPatientExperiment(\"jurassic-jumbo\", \"volition\", f\"../data/agent_patient/change_of_state_2_prefix_{s}.json\", run_ai21_jumbo_prompt, 1, jurassic_kwargs)\n",
    "    t0 = time.time()\n",
    "    jurassic_object_control_experiment.run(overwrite=False, rate_limit_delay=60, rate_limit_count=19)\n",
    "\n",
    "    jurassic_df = jurassic_object_control_experiment.format_results()\n",
    "    t1 = time.time()\n",
    "    elapsed = t1 - t0\n",
    "    jurassic_df.to_csv(f\"../agent_patient_results_2/jurassic_jumbo_change_of_state_prefix_{s}.csv\")\n",
    "    time.sleep(max(0, 60 - elapsed + 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec6008f546f3cd66431ed7a4f2e2b63949ea9a2fd324a00b9368fd8a5a5333f5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('openai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
